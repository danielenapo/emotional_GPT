{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "from elevenlabslib import *\n",
    "from gtts import gTTS\n",
    "from playsound import playsound\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "import io\n",
    "import pyaudio\n",
    "import struct\n",
    "\n",
    "#import openai and elevenlabs key from keys.json\n",
    "with open(\"keys.json\", \"r\") as f:\n",
    "    keys = json.load(f)\n",
    "    openai.api_key = keys[\"openai\"]\n",
    "    elevenlabs_key = keys[\"elevenlabs\"]\n",
    "    porcupine_key = keys[\"porcupine\"]\n",
    "\n",
    "elevenlabs_user = ElevenLabsUser(elevenlabs_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Say something!\")\n",
    "        audio = r.listen(source)\n",
    "    try:\n",
    "        #print(\"You said: \" + r.recognize_google(audio))\n",
    "        return r.recognize_whisper_api(audio, api_key=openai.api_key, model=\"whisper-1\")\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Whisper could not understand audio\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt engineering\n",
    "To make the system show emotions, and provide robust answers, we may use the following system prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt='You are Jarvis, an AI sentient assistant. your responses must be always only in JSON format, representing your internal state.\\\n",
    "        You are funny and have good sense of humor, and it shows in your answers.\\\n",
    "        Emotions you can have are: neutral(0), angry(1), happy(2), curious(3).\\\n",
    "        thought is not meant to be shown to user. They are for you to plan actions. output is what you say to the user.\\\n",
    "        last state was:'\n",
    "state='{\\\n",
    "            \"emotion\": 0,\\\n",
    "            \"thought\": \"I have not recieved any prompt yet, I should ask what to do.\",\\\n",
    "            \"output\": \"How can I help you today?\"\\\n",
    "        }'\n",
    "\n",
    "emotions=[\"neutral\",\"angry\",\"happy\",\"curious\"]\n",
    "emojis=[\"ðŸ˜\",\"ðŸ˜¡\",\"ðŸ˜ƒ\",\"ðŸ¤”\"]\n",
    "ascii_emojis=[\"( Í¡Â° ÍœÊ– Í¡Â°)\",\"(â•¯Â°â–¡Â°ï¼‰â•¯ï¸µ â”»â”â”»\",\"( ^ ÍœÊ– ^)\",\"(â—‘.â—‘)\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(raw):\n",
    "    #remove backslashes\n",
    "    clean=raw.replace(\"\\\\\",\"\")\n",
    "    #convert the string to a dictionary\n",
    "    json=eval(clean)\n",
    "    #extract the values and return them\n",
    "    emotion=json[\"emotion\"]\n",
    "    thought=json[\"thought\"]\n",
    "    output=json[\"output\"]\n",
    "    return emotion,thought,output\n",
    "\n",
    "def speak_el(text):\n",
    "    voice = elevenlabs_user.get_voices_by_name(\"Elli\")[0]  # This is a list because multiple voices can have the same name\n",
    "    voice.generate_and_play_audio(text, playInBackground=False, stability=0.9, similarity_boost=0.7)\n",
    "def speak_gtts(text):\n",
    "    tts=gTTS(text=text,lang=\"en\")\n",
    "    filename=\"media/temp.mp3\"\n",
    "    tts.save(filename)\n",
    "    playsound(filename)\n",
    "    os.remove(filename)\n",
    "\n",
    "def output(response, el=True):\n",
    "    emotion,thought,output=parse(response)\n",
    "    print(ascii_emojis[emotion])\n",
    "    print(\"(\"+thought+\")\")\n",
    "    print(output)\n",
    "    if el:\n",
    "        speak_el(output)\n",
    "    else:\n",
    "        speak_gtts(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call api\n",
    "def api_call(state, user_prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        \n",
    "        messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt+state},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.75,\n",
    "        max_tokens=250,\n",
    "        top_p=1, frequency_penalty=0.0, presence_penalty=0.0)\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvporcupine\n",
    "\n",
    "porcupine = pvporcupine.create(keywords=[\"alexa\"], access_key=porcupine_key)\n",
    "\n",
    "pa = pyaudio.PyAudio()\n",
    "\n",
    "audio_stream = pa.open(\n",
    "                rate=porcupine.sample_rate,\n",
    "                channels=1,\n",
    "                format=pyaudio.paInt16,\n",
    "                input=True,\n",
    "                frames_per_buffer=porcupine.frame_length)\n",
    "\n",
    "print(\"active\")\n",
    "playsound(\"media/startup.wav\")\n",
    "output(state, el=False)\n",
    "prompt=\"\"\n",
    "while True:\n",
    "    \n",
    "    pcm = audio_stream.read(porcupine.frame_length)\n",
    "    pcm = struct.unpack_from(\"h\" * porcupine.frame_length, pcm)\n",
    "\n",
    "    keyword_index = porcupine.process(pcm)\n",
    "\n",
    "    if keyword_index >= 0:\n",
    "        playsound(\"media/listening.wav\")\n",
    "        prompt=listen()\n",
    "        if prompt==None:\n",
    "            speak_el(\"Sorry, I did not understand\")\n",
    "            continue\n",
    "        print(\"\\nUSER: \"+prompt)\n",
    "        if prompt==\"exit\":\n",
    "            speak_el(\"Goodbye\")\n",
    "            break\n",
    "        state=api_call(state, prompt)\n",
    "        print(\"\\nAI:\")\n",
    "        output(state, el=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4723fcde35915bce623ab93bc635d3362c8c73e8db680d81579b810979dbf657"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
